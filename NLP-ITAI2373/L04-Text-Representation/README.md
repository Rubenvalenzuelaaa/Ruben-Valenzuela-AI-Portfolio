# L04 – Text Representation

In this lab, we explored several key techniques for representing text data, including:

- Bag of Words (BoW)
- Term Frequency–Inverse Document Frequency (TF-IDF)
- N-grams
- Word Embeddings using pre-trained models

The goal was to understand how different text representations affect model performance.

## Included Files

- `L04_Ruben_Valenzuela_ITAI_2373.ipynb` – Jupyter notebook with all implementations and comparisons
- `L04_Journal_Ruben_ITAI_2373.docx` – Reflection journal describing insights and lessons learned
